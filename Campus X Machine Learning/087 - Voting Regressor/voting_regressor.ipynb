{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e916867-597f-4275-8be9-58e67cc0e8e6",
   "metadata": {},
   "source": [
    "## Voting Regressor\n",
    "\n",
    "Voting Regressor is an ensemble meta-estimator in scikit-learn that combines the predictions of multiple base regressor models to make a final prediction. It aggregates the predictions from individual regressor models by averaging their outputs.\n",
    "\n",
    "Here's an explanation of the Voting Regressor and its hyperparameters:\n",
    "\n",
    "- **Concept**: Voting Regressor combines the predictions from multiple base regressor models using a voting scheme, where each model's prediction contributes equally to the final prediction. The final prediction is obtained by averaging the predictions of individual regressor models.\n",
    "\n",
    "- **Implementation**: It can use various types of base regressors, such as linear regression, decision trees, support vector machines, etc. The Voting Regressor aggregates the predictions of these base regressors to produce a final prediction.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Improves prediction accuracy and robustness by leveraging the collective knowledge of multiple regressor models.\n",
    "  - Reduces overfitting and generalizes well to unseen data by combining diverse models.\n",
    "  - Easy to implement and use, similar to other ensemble methods in scikit-learn.\n",
    "\n",
    "### Hyperparameters:\n",
    "\n",
    "1. **estimators**: This parameter specifies the list of base regressor models to be included in the voting ensemble. It is typically a list of tuples, where each tuple contains a name or identifier for the regressor and the regressor object itself.\n",
    "\n",
    "2. **voting**: This parameter determines the type of voting scheme to be used for combining predictions. It can take one of the following values:\n",
    "   - 'hard': Hard voting, where the final prediction is based on the majority vote of individual regressor models.\n",
    "   - 'soft': Soft voting, where the final prediction is based on the average of predicted probabilities or scores from individual regressor models.\n",
    "\n",
    "3. **weights**: This parameter allows specifying the weights assigned to each base regressor model in the ensemble. It is used when soft voting is employed, allowing certain models to have more influence on the final prediction than others.\n",
    "\n",
    "4. **n_jobs**: This parameter specifies the number of CPU cores to use for parallelizing the computation. It speeds up the fitting process when multiple regressor models are trained simultaneously.\n",
    "\n",
    "5. **verbose**: This parameter controls the verbosity of the output during fitting. Higher values provide more verbose output for debugging purposes.\n",
    "\n",
    "By adjusting these hyperparameters, you can customize the behavior of the Voting Regressor to suit the characteristics of your dataset and the specific requirements of your regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e23197-8b86-4af7-9345-0c9617bc631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea827ec-c2ca-49e2-a378-c8622a9a5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438e43e5-d80b-4919-926b-aa474617f2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5867f4-119c-4e6f-ae75-361afab84ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea28864a-d13d-485b-8c3b-62b8b41a0906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d99d6a0-1187-4dce-910f-d5cfadd06e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120475b0-ce29-4b0b-9b6c-90db4d4bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827aea46-0169-40e6-b054-722f5a799abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7832f7c5-5662-48d1-a75d-c6893668951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', lr), ('dt', dt), ('svr' , svr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5229af39-7541-498f-b4c4-1cf441744c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.2\n",
      "dt -0.27\n",
      "svr -0.41\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    x = cross_val_score(estimator[1], X, y,cv= 10, scoring='r2')\n",
    "    print(estimator[0], np.round(np.mean(x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ca5f84-85f9-4349-bfb7-0b862f2ee212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor 0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "vr = VotingRegressor(estimators)\n",
    "scores = cross_val_score(vr, X, y, scoring= 'r2', cv=10)\n",
    "print('Voting Regressor', np.round(np.mean(scores), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27bbc523-9730-4fd6-bc76-c34edc0a0b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For i = 1, j = 1, k = 1 0.44\n",
      "For i = 1, j = 1, k = 2 0.35\n",
      "For i = 1, j = 1, k = 3 0.26\n",
      "For i = 1, j = 2, k = 1 0.43\n",
      "For i = 1, j = 2, k = 2 0.39\n",
      "For i = 1, j = 2, k = 3 0.34\n",
      "For i = 1, j = 3, k = 1 0.34\n",
      "For i = 1, j = 3, k = 2 0.38\n",
      "For i = 1, j = 3, k = 3 0.39\n",
      "For i = 2, j = 1, k = 1 0.46\n",
      "For i = 2, j = 1, k = 2 0.42\n",
      "For i = 2, j = 1, k = 3 0.33\n",
      "For i = 2, j = 2, k = 1 0.4\n",
      "For i = 2, j = 2, k = 2 0.45\n",
      "For i = 2, j = 2, k = 3 0.41\n",
      "For i = 2, j = 3, k = 1 0.45\n",
      "For i = 2, j = 3, k = 2 0.41\n",
      "For i = 2, j = 3, k = 3 0.4\n",
      "For i = 3, j = 1, k = 1 0.44\n",
      "For i = 3, j = 1, k = 2 0.43\n",
      "For i = 3, j = 1, k = 3 0.4\n",
      "For i = 3, j = 2, k = 1 0.39\n",
      "For i = 3, j = 2, k = 2 0.41\n",
      "For i = 3, j = 2, k = 3 0.42\n",
      "For i = 3, j = 3, k = 1 0.38\n",
      "For i = 3, j = 3, k = 2 0.46\n",
      "For i = 3, j = 3, k = 3 0.44\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    for j in range(1,4):\n",
    "        for k in range(1,4):\n",
    "            vr = VotingRegressor(estimators, weights= [i,j,k])\n",
    "            scores = cross_val_score(vr, X, y, scoring= 'r2', cv=10)\n",
    "            print('For i = {}, j = {}, k = {}'.format(i,j,k), np.round(np.mean(scores), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eda67a5-3d03-4a86-bd87-2ba411bb0f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "vr = VotingRegressor(estimators, weights= [2,1,1])\n",
    "scores = cross_val_score(vr, X, y, scoring= 'r2', cv=10)\n",
    "print(np.round(np.mean(scores), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
