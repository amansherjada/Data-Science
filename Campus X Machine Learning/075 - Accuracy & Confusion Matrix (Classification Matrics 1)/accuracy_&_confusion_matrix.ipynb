{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352dbd24-0433-4835-8f10-8c3eb3812d7e",
   "metadata": {},
   "source": [
    "### Classification metrics\n",
    "\n",
    "Classification metrics are measures used to evaluate the performance of machine learning models that are used for classification tasks. In classification, the goal is to predict a categorical label or class for a given input instance. Some common classification metrics include:\r\n",
    "\r\n",
    "1. **Accuracy**: The proportion of correctly classified instances out of the total instances.\r\n",
    "\r\n",
    "2. **Precision**: The proportion of true positive predictions (correctly predicted positive instances) out of all positive predictions (true positives + false positives). Precision focuses on the accuracy of positive predictions.\r\n",
    "\r\n",
    "3. **Recall (Sensitivity)**: The proportion of true positive predictions out of all actual positive instances (true positives + false negatives). Recall measures the ability of the model to capture all positive instances.\r\n",
    "\r\n",
    "4. **F1 Score**: The harmonic mean of precision and recall. It provides a balanced measure between precision and recall.\r\n",
    "\r\n",
    "5. **Specificity**: The proportion of true negative predictions (correctly predicted negative instances) out of all actual negative instances (true negatives + false positives). Specificity measures the ability of the model to correctly identify negative instances.\r\n",
    "\r\n",
    "6. **ROC Curve (Receiver Operating Characteristic Curve)**: A graphical representation of the true positive rate (recall) against the false positive rate at various threshold settings. It helps to visualize the trade-off between sensitivity and specificity.\r\n",
    "\r\n",
    "7. **AUC (Area Under the ROC Curve)**: The area under the ROC curve. AUC provides an aggregate measure of performance across all possible classification thresholds.\r\n",
    "\r\n",
    "8. **Confusion Matrix**: A matrix that summarizes the performance of a classification model by showing the counts of true positive, false positive, true negative, and false negative predictions.\r\n",
    "\r\n",
    "These metrics provide insights into different aspects of a classifier's performance and help in evaluating its effectiveness for a particular task. The choice of metrics depends on the specific requirements and constraints of the problem at hand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797219a2-9850-41e5-a977-64b9c918207e",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "![](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8dc0d74-3a1a-444c-aeb1-f1b0ba55d310_320x199.png)\n",
    "\n",
    "Accuracy is a common classification metric that measures the proportion of correctly classified instances out of the total instances. It's calculated using the formula:\n",
    "\n",
    "`Accuracy = Number of Correct Predictions / Total Number of Predictions`\n",
    "\n",
    "Let's illustrate accuracy with a simple example:\n",
    "\n",
    "Suppose you have a dataset of 100 emails labeled as either \"spam\" or \"not spam\". You've built a machine learning model to classify these emails. After training the model and making predictions, you find the following results:\n",
    "\n",
    "- Correctly classified spam emails: 80\n",
    "- Correctly classified non-spam emails: 15\n",
    "- Incorrectly classified spam emails: 3\n",
    "- Incorrectly classified non-spam emails: 2\n",
    "\n",
    "To calculate accuracy:\n",
    "\n",
    "`Total Number of Predictions = Total Correct Predictions + Total Incorrect Predictions`\n",
    "\n",
    "Total Number of Predictions = 80 + 15 + 3 + 2 = 100\n",
    "\n",
    "Accuracy = 80 + 15 / 100 = 95 / 100 = `0.95`\n",
    "\n",
    "So, the accuracy of your model is 95%. This means that 95 out of 100 emails were correctly classified by your model.\n",
    "\n",
    "In simple terms, accuracy tells you how often your model makes the correct prediction out of all predictions made. However, it's important to note that accuracy may not be the best metric for all situations, especially when dealing with imbalanced datasets where one class is much more prevalent than the other. In such cases, other metrics like precision, recall, or F1 score might provide a better understanding of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855c632-06f9-407e-9d72-85475d344c94",
   "metadata": {},
   "source": [
    "### Accuracy for multi-class classification\n",
    "\n",
    "Let's explain accuracy for multi-class classification using the famous Iris dataset, which consists of 150 samples of iris flowers, each with four features: sepal length, sepal width, petal length, and petal width. The task is to classify each iris sample into one of three species: Setosa, Versicolor, or Virginica.\n",
    "\n",
    "Suppose we have a machine learning model trained on the Iris dataset to classify iris flowers into three species: Setosa, Versicolor, and Virginica.\n",
    "\n",
    "After training the model and making predictions on a test dataset, we obtain the following results:\n",
    "\n",
    "- Correctly classified Setosa flowers: 48\n",
    "- Correctly classified Versicolor flowers: 45\n",
    "- Correctly classified Virginica flowers: 47\n",
    "\n",
    "- Incorrectly classified Setosa flowers: 2\n",
    "- Incorrectly classified Versicolor flowers: 5\n",
    "- Incorrectly classified Virginica flowers: 3\n",
    "\n",
    "To calculate accuracy:\n",
    "\n",
    "`Total Number of Predictions = Total Correct Predictions + Total Incorrect Predictions`\n",
    "\n",
    "Total Number of Predictions = 48 + 45 + 47 + 2 + 5 + 3 = 150\n",
    "\n",
    "Accuracy = (48 + 45 + 47) / 150\n",
    "\n",
    "Accuracy = 140 / 150\n",
    "\n",
    "`Accuracy = 0.9333 (rounded to four decimal places)`\n",
    "\n",
    "So, the accuracy of our multi-class classification model on the Iris dataset is approximately 93.33%. This means that about 93.33% of the iris flowers in our test dataset were correctly classified by the model.\n",
    "\n",
    "So, the accuracy of your model for the Iris dataset is approximately 93.3%. This means that out of the total 150 iris samples, the model correctly classified around 93.3% of them.\n",
    "\n",
    "In multi-class classification, accuracy gives you an overall measure of how well your model performs across all classes. However, it's important to note that accuracy may not always be the most informative metric, especially if the classes are imbalanced or if certain types of errors are more costly than others. In such cases, you may want to consider other metrics like precision, recall, or F1 score for a more nuanced evaluation of your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe743e83-cdaf-45db-a079-3c010f235bc0",
   "metadata": {},
   "source": [
    "### How much accuracy is good?\n",
    "\n",
    "It depends on the problem we are solving\n",
    "\n",
    "\n",
    "\n",
    "The level of accuracy considered \"good\" depends on various factors, including the specific context of the problem, the nature of the data, and the consequences of errors.\r\n",
    "\r\n",
    "Here are some general considerations:\r\n",
    "\r\n",
    "1. **Baseline Accuracy**: Before assessing whether a model's accuracy is good, it's essential to establish a baseline. This could be the accuracy of a simple baseline model or the accuracy one would expect by random chance. Your model should perform significantly better than this baseline to be considered effective.\r\n",
    "\r\n",
    "2. **Domain Requirements**: The acceptable level of accuracy often varies depending on the domain and the specific task. For example, in certain medical diagnoses or financial fraud detection tasks, even a small increase in accuracy can be crucial. On the other hand, in less critical applications, a slightly lower accuracy might be acceptable.\r\n",
    "\r\n",
    "3. **Cost of Errors**: Consider the consequences of false positives and false negatives. In some scenarios, false positives (Type I errors) might be more tolerable than false negatives (Type II errors), or vice versa. The relative costs of these errors can influence what level of accuracy is deemed acceptable.\r\n",
    "\r\n",
    "4. **Imbalance in Classes**: If the classes in your dataset are highly imbalanced (i.e., one class is much more prevalent than others), accuracy alone might not be a reliable metric. In such cases, other metrics like precision, recall, or F1 score may provide a more nuanced evaluation of the model's performance.\r\n",
    "\r\n",
    "5. **Trade-offs with Other Metrics**: Sometimes, optimizing for accuracy might not be the best strategy, especially if there are trade-offs with other important metrics. For instance, achieving higher accuracy might come at the cost of lower precision or recall. The choice of evaluation metrics should align with the specific goals of the project.\r\n",
    "\r\n",
    "In summary, while higher accuracy is generally desirable, what constitutes \"good\" accuracy is subjective and depends on the specific requirements and constraints of the problem at hand. It's essential to consider various factors and metrics when evaluating the performance of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b87e29-fe89-440b-9d72-73c4688a9f42",
   "metadata": {},
   "source": [
    "### The problem with Accuracy Score?\r\n",
    "While accuracy score is a commonly used metric for evaluating classification models, it does have some limitations and potential drawbacks:\r\n",
    "\r\n",
    "1. **Sensitivity to Class Imbalance**: Accuracy score can be misleading when dealing with imbalanced datasets, where one class is much more prevalent than others. In such cases, a model can achieve high accuracy by simply predicting the majority class for most instances, even if it performs poorly on the minority class(es). This can give a false impression of the model's effectiveness.\r\n",
    "\r\n",
    "2. **Failure to Capture Class Distribution**: Accuracy alone does not provide insight into the distribution of predictions across different classes. A model may have high accuracy overall but still perform poorly on specific classes. This lack of granularity can be problematic, especially in applications where certain classes are more critical or costly to misclassify.\r\n",
    "\r\n",
    "3. **Misleading Performance Assessment**: In some cases, accuracy may not accurately reflect the true performance of a model. For example, if the cost of false positives and false negatives differs significantly, accuracy alone may not adequately capture the impact of these errors. This can lead to suboptimal model selection or deployment decisions.\r\n",
    "\r\n",
    "4. **Doesn't Account for Prediction Confidence**: Accuracy treats all correct predictions equally, regardless of the confidence level of those predictions. A model that is highly confident in its correct predictions is treated the same as one that is uncertain about its correct predictions. This lack of consideration for prediction confidence can be problematic, especially in applications where confidence in predictions is essential.\r\n",
    "\r\n",
    "5. **Inability to Differentiate Types of Errors**: Accuracy does not distinguish between different types of prediction errors (e.g., false positives vs. false negatives). Depending on the application, the consequences of these errors may vary significantly. Other metrics such as precision, recall, and F1 score provide more nuanced insights into the types of errors made by the model.\r\n",
    "\r\n",
    "In summary, while accuracy score is a straightforward metric to interpret, it should be used with caution, especially in scenarios with imbalanced classes or differential costs associated with prediction errors. It's often beneficial to complement accuracy with other evaluation metrics to gain a more comprehensive understanding of a model's erformance.\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331a52b-1671-4a43-b3a9-2a8347d857e6",
   "metadata": {},
   "source": [
    "```\n",
    "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
    "\n",
    "Parameters:\n",
    "y_true : 1d array-like, or label indicator array / sparse matrix\n",
    "Ground truth (correct) labels.\n",
    "\n",
    "y_pred : 1d array-like, or label indicator array / sparse matrix\n",
    "Predicted labels, as returned by a classifier.\n",
    "\n",
    "normalize : bool, default=True\n",
    "If False, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.\n",
    "\n",
    "sample_weight : array-like of shape (n_samples,), default=None\n",
    "Sample weights.\n",
    "\n",
    "Returns:\n",
    "scorefloat\n",
    "If normalize == True, return the fraction of correctly classified samples (float), else returns the number of correctly classified samples (int).\n",
    "\n",
    "The best performance is 1 with normalize == True and the number of samples with normalize == False.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b00e63-a262-4344-afe2-4bccb2319eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cdf7a0-a8bc-483f-b5d1-f1fbc0ede0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,0:-1],df.iloc[:,-1],test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ff3598-8868-4495-8539-905a40e6bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0b063d-8a75-41c0-9d94-c08659479c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4cc813-2be1-4acd-87f8-2dcfa4c68e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)\n",
    "clf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833f19cf-dbb0-43bc-9a1a-8a8cef803892",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test)\n",
    "y_pred2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7668b40-38d7-4612-bfb3-4f74588ecb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression 0.8390243902439024\n",
      "Accuracy of Decision Trees 0.9804878048780488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of Logistic Regression\",accuracy_score(y_test,y_pred1))\n",
    "print(\"Accuracy of Decision Trees\",accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152503e-bcca-4b56-8e74-9ffd316c424f",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "![Confusion Matrix](https://miro.medium.com/v2/resize:fit:1218/1*jMs1RmSwnYgR9CsBw-z1dw.png)\n",
    "\n",
    "A confusion matrix is a table that visualizes the performance of a classification model by summarizing the counts of correct and incorrect predictions made by the model on a dataset. It breaks down the model's predictions into four categories based on the actual and predicted classes:\r\n",
    "\r\n",
    "1. True Positives (TP): Instances that are correctly predicted as belonging to the positive class.\r\n",
    "2. True Negatives (TN): Instances that are correctly predicted as belonging to the negative class.\r\n",
    "3. False Positives (FP): Instances that are incorrectly predicted as belonging to the positive class when they actually belong to the negative class. Also known as Type I errors.\r\n",
    "4. False Negatives (FN): Instances that are incorrectly predicted as belonging to the negative class when they actually belong to the positive class. Also known as Type II errors.\r\n",
    "\r\n",
    "The confusion matrix helps in evaluating the performance of a classification model by providing insights into its ability to correctly classify instances across different classes. It is a crucial tool for assessing the accuracy, precision, recall, F1 score, and other performance metrics of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5c5dd-dad3-499d-8a28-2c35db48b6a9",
   "metadata": {},
   "source": [
    "\r\n",
    "Imagine you have built a machine learning model to classify emails as either spam or not spam. The confusion matrix helps you understand how well your model is performing by breaking down its predictions into four categories:\r\n",
    "\r\n",
    "1. **True Positives (TP)**: These are the emails that your model correctly predicted as spam.\r\n",
    "\r\n",
    "2. **True Negatives (TN)**: These are the emails that your model correctly predicted as not spam.\r\n",
    "\r\n",
    "3. **False Positives (FP)**: These are the emails that your model incorrectly predicted as spam when they are actually not spam. (Also known as Type I errors)\r\n",
    "\r\n",
    "4. **False Negatives (FN)**: These are the emails that your model incorrectly predicted as not spam when they are actually spam. (Also known as Type II errors)e's a simple example to illustrate:\r\n",
    "\r\n",
    "Let's say you tested your model on 100 emails, and here are the results:\r\n",
    "\r\n",
    "- True Positives (TP): Your model correctly identified 30 emails as spam.\r\n",
    "- True Negatives (TN): Your model correctly identified 60 emails as not spam.\r\n",
    "- False Positives (FP): Your model incorrectly marked 5 emails as spam when they were not.\r\n",
    "- False Negatives (FN): Your model missed 5 spam emails and classified them as not spam.\r\n",
    "\r\n",
    "Now, you can visualize these results in a matrix format like this:\r\n",
    "\r\n",
    "```\r\n",
    "               Predicted Not Spam   Predicted Spam\r\n",
    "Actual Not Spam       TN (60)             FP (5)\r\n",
    "Actual Spam           FN (5)              TP (30)\r\n",
    "```\r\n",
    "\r\n",
    "In this confusion matrix:\r\n",
    "- The top-left cell (TN) represents the emails correctly classified as not spam.\r\n",
    "- The top-right cell (FP) represents the emails incorrectly classified as spam.\r\n",
    "- The bottom-left cell (FN) represents the spam emails incorrectly classified as not spam.\r\n",
    "- The bottom-right cell (TP) represents the spam emails correctly classified as spam.\r\n",
    "\r\n",
    "By looking at this matrix, you can see where your model is making mistakes and where it's performing well. This helps you understand the strengths and weaknesses of your model and can guide you in improving its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18e6a63-2e9a-4ea7-8dd3-fc2eefc17a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ba03db-2db6-4013-aa39-bfa7b675317b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef1d0f-da51-4438-9c38-b609969b18ae",
   "metadata": {},
   "source": [
    "In scikit-learn (sklearn), the top-left cell of a confusion matrix can represent both True Negatives (TN) and True Positives (TP), depending on the definition of the classes. The confusion matrix is a 2x2 array, and the meaning of the top-left cell changes based on the order of the classes.\n",
    "\n",
    "[[TN, FP],  \n",
    "\n",
    " [FN, TP]]  \n",
    "\n",
    "or\n",
    "\n",
    " [[TP, FN],\n",
    "\n",
    " [FP, TN]]\n",
    "\n",
    "The top-left cell of the confusion matrix represents True Negatives (TN) when it corresponds to the actual negative class (0) and the predicted negative class (0), while it represents True Positives (TP) when it corresponds to the actual positive class (1) and the predicted positive class (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60bc399-401a-42ef-80ca-8eab04d85000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82, 23],\n",
       "       [10, 90]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test ,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9ee73b-076d-45c4-b08d-5311fa3a1cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82 + 23 + 10 + 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481683e2-9e62-497d-bea5-4a54214e3428",
   "metadata": {},
   "source": [
    "#### We can also calculate the Accuracy Scroce using confusion matrix but not vica versa \n",
    "\n",
    "![](https://www.nomidl.com/wp-content/uploads/2022/02/image-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7bab9-14bb-4cc7-a911-2320d636f9ec",
   "metadata": {},
   "source": [
    "Type I and Type II errors are concepts commonly used in hypothesis testing and binary classification problems. Here's an explanation of each:\r\n",
    "\r\n",
    "1. **Type I Error**:\r\n",
    "   - Also known as a \"false positive.\"\r\n",
    "   - Occurs when the null hypothesis is incorrectly rejected when it is actually true.\r\n",
    "   - In the context of binary classification:\r\n",
    "     - Type I error occurs when a negative instance is incorrectly classified as positive.\r\n",
    "   - Example: In a medical test for a disease, a Type I error would happen if the test indicates a person has the disease when they do not actually have it.\r\n",
    "\r\n",
    "2. **Type II Error**:\r\n",
    "   - Also known as a \"false negative.\"\r\n",
    "   - Occurs when the null hypothesis is incorrectly accepted when it is actually false.\r\n",
    "   - In the context of binary classification:\r\n",
    "     - Type II error occurs when a positive instance is incorrectly classified as negative.\r\n",
    "   - Example: In a medical test for a disease, a Type II error would happen if the test indicates a person does not have the disease when they actually do have it.\r\n",
    "\r\n",
    "In summary, Type I and Type II errors represent the two possible mistakes that can occur in hypothesis testing or binary classification, depending on whether the null hypothesis is true or false and how it is classified or rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c549879-7442-4ed0-bcc5-7145e5dff258",
   "metadata": {},
   "source": [
    "### Multi-Class Confusion Matrix with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36117e6f-2c7f-4aed-a171-9f3807782bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Train a decision tree classifier on the training set\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81c926-04d8-4e35-ab6a-30addd6b78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagonal elements are the True predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552531fa-a33c-482a-8212-be3fb144d162",
   "metadata": {},
   "source": [
    "### When accuracy score is misleading?\n",
    "\n",
    "The accuracy score can be misleading in certain scenarios, especially when the dataset is imbalanced, or when different types of errors have significantly different consequences. Here are some situations where accuracy might be misleading:\r\n",
    "\r\n",
    "1. **Imbalanced Datasets**: In datasets where one class is significantly more frequent than the others, accuracy can be high simply by predicting the majority class all the time. However, this doesn't necessarily mean that the model is performing well. For example, if you have 95% of instances belonging to class A and 5% belonging to class B, a model that always predicts class A will achieve 95% accuracy. In such cases, accuracy alone doesn't provide a clear picture of the model's performance, especially for the minority class.\r\n",
    "\r\n",
    "2. **Different Costs of Errors**: In many real-world scenarios, the cost of false positives and false negatives can be significantly different. For instance, in medical diagnosis, a false negative (predicting a patient doesn't have a disease when they actually do) might have far more severe consequences than a false positive. In such cases, accuracy might not adequately capture the performance of the model because it treats all types of errors equally.\r\n",
    "\r\n",
    "3. **Class Distribution Shift**: If the distribution of classes changes over time, accuracy may not reflect the model's performance accurately. For example, if a model is trained on data from one time period and tested on data from another period where the class distribution has shifted, accuracy might not be a reliable metric.\r\n",
    "\r\n",
    "4. **Misclassification of Specific Classes**: Accuracy does not provide insight into which classes are being misclassified. A model might have high accuracy but perform poorly on certain classes.\r\n",
    "\r\n",
    "In these cases, it's essential to look at other metrics such as precision, recall, F1-score, or area under the ROC curve (AUC-ROC) to gain a more comprehensive understanding of the model's performance, especially regarding specific classes or types of errors. Additionally, domain knowledge and understanding the context of the problem are crucial for interpreting model performance metrics accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
