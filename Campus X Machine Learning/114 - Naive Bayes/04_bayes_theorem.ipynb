{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e477f670-3dc8-42ed-bc3d-52476153c2c4",
   "metadata": {},
   "source": [
    "### Bayes' theorem\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory that describes how to update or revise the probability of an event based on new evidence or information. It provides a way to calculate the probability of an event given prior knowledge or beliefs about related events.\n",
    "\n",
    "Bayes' theorem is formulated as follows:\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$\n",
    "\n",
    "where:\n",
    "- $P(A|B)$ is the probability of event A occurring given that event B has occurred.\n",
    "- $P(B|A)$ is the probability of event B occurring given that event A has occurred.\n",
    "- $P(A)$ is the prior probability of event A (the probability of event A occurring before considering any new evidence).\n",
    "- $P(B)$ is the prior probability of event B (the probability of event B occurring before considering any new evidence).\n",
    "\n",
    "Bayes' theorem can be understood intuitively as follows:\n",
    "\n",
    "1. **Prior Probability (Prior Belief)**:\n",
    "   - Before observing any new evidence, we have a prior belief or knowledge about the probability of event A occurring $(P(A))$ and event B occurring $(P(B))$.\n",
    "\n",
    "2. **Likelihood**:\n",
    "   - After observing new evidence (event B), we want to update our belief about the probability of event A occurring based on this evidence. The likelihood term $(P(B|A)$ represents how likely the observed evidence (event B) would be if event A were true.\n",
    "\n",
    "3. **Normalization**:\n",
    "   - The denominator $(P(B)$ acts as a normalizing factor to ensure that the probabilities are scaled appropriately. It represents the total probability of observing event B across all possible scenarios.\n",
    "\n",
    "4. **Posterior Probability (Updated Belief)**:\n",
    "   - The numerator $(P(B|A) \\times P(A))$ represents the joint probability of events A and B occurring together. By dividing this joint probability by the total probability of observing event B, we obtain the posterior probability $(P(A|B))$, which represents our updated belief or knowledge about the probability of event A occurring given the observed evidence (event B).\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, and medical diagnostics, to make predictions and make decisions based on uncertain or incomplete information. It provides a principled framework for updating beliefs in light of new evidence, making it a powerful tool for reasoning under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d448db7-3562-4754-a871-1b3cd618d998",
   "metadata": {},
   "source": [
    "### Proof Bayes theorem\n",
    "\n",
    "Bayes' theorem can be derived using the definition of conditional probability and the definition of the intersection of events. Let's start with the definition of conditional probability:\n",
    "\n",
    "$$[P(A|B) = \\frac{P(A \\cap B)}{P(B)}]$$\n",
    "\n",
    "Similarly, we can express $P(B|A)$ using conditional probability:\n",
    "\n",
    "$$[P(B|A) = \\frac{P(B \\cap A)}{P(A)}]$$\n",
    "\n",
    "Now, we can rearrange the second equation to solve for $P(B \\cap A)$:\n",
    "\n",
    "$$P(B \\cap A) = P(B|A) \\times P(A)$$\n",
    "\n",
    "Now, substituting this expression for $P(B \\cap A)$ into the first equation, we get:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "This is Bayes' theorem.\n",
    "\n",
    "So, Bayes' theorem essentially states that the probability of event A occurring given that event B has occurred is equal to the probability of event B occurring given that event A has occurred, multiplied by the probability of event A occurring, divided by the probability of event B occurring.\n",
    "\n",
    "This theorem is a fundamental concept in probability theory and has wide applications in various fields, including statistics, machine learning, and medical diagnostics. It provides a way to update our beliefs or knowledge about the probability of an event based on new evidence or information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90628db-31d5-4fdb-bc5b-9ab2078ae429",
   "metadata": {},
   "source": [
    "### Problem based  upon Bayes theorem\n",
    "\n",
    "Example involving medical diagnostics, where Bayes' theorem is commonly applied.\n",
    "\n",
    "Suppose there is a medical test to detect a rare disease, and the test is not perfect; it can sometimes give false positive or false negative results. Let's define the following events:\n",
    "\n",
    "- Event A: Having the disease.\n",
    "- Event B: Testing positive for the disease.\n",
    "\n",
    "Suppose the following probabilities are known:\n",
    "- The probability of having the disease, $P(A)$, is 0.01 (1% of the population has the disease).\n",
    "- The probability of testing positive given that the person has the disease, $P(B|A)$, is 0.95 (the sensitivity of the test, meaning it correctly identifies 95% of the true positive cases).\n",
    "- The probability of testing negative given that the person does not have the disease, $P(\\neg B | \\neg A)$, is 0.90 (the specificity of the test, meaning it correctly identifies 90% of the true negative cases).\n",
    "\n",
    "We can use Bayes' theorem to calculate the probability of actually having the disease given that the test result is positive, $P(A|B)$.\n",
    "\n",
    "Bayes' theorem states:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "where:\n",
    "- $P(B)$ can be calculated using the law of total probability, considering both true positive and false positive cases:\n",
    "\n",
    "$$P(B) = P(B|A) \\times P(A) + P(B|\\neg A) \\times P(\\neg A)$$\n",
    "\n",
    "- $P(B|\\neg A)$ is the probability of testing positive given that the person does not have the disease, which is the complement of the specificity (1 - specificity).\n",
    "\n",
    "Now, let's plug in the values:\n",
    "\n",
    "$$P(B) = (0.95 \\times 0.01) + (0.10 \\times 0.99)$$\n",
    "\n",
    "$$P(B) = 0.0095 + 0.099 = 0.1085$$\n",
    "\n",
    "Now, we can use Bayes' theorem to calculate the probability of having the disease given a positive test result:\n",
    "\n",
    "$$P(A|B) = \\frac{0.95 \\times 0.01}{0.1085}$$\n",
    "\n",
    "$$P(A|B) \\approx \\frac{0.0095}{0.1085} \\approx 0.0876$$\n",
    "\n",
    "So, even if someone tests positive for the disease, the probability of actually having the disease is only about 8.76%. This illustrates the importance of considering the accuracy of the test (sensitivity and specificity) in interpreting the results, as well as the base rate of the disease in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104fc77-a8f2-4f81-94d1-2d39b155139c",
   "metadata": {},
   "source": [
    "### Problem based upon Bayes theorem\n",
    "\n",
    "```\n",
    "In a factory, there are three machines (Machine 1, Machine 2, and Machine 3) that produce markers. Machine 1 produces 20% of the total markers, Machine 2 produces 20%, and Machine 3 produces the remaining 50%. Additionally, Machine 1 produces 5% defective markers, Machine 2 produces 3% defective markers, and Machine 3 produces 1% defective markers.\n",
    "\n",
    "What is the probability of selecting a defective marker that was produced by Machine 3? Explain using Bayes' theorem\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6fb9a-6bd4-4125-b762-fc98939777a7",
   "metadata": {},
   "source": [
    "Let's solve the problem step by step using Bayes' theorem.\n",
    "\n",
    "Given:\n",
    "- $P(M_1) = 0.20$ (Probability of selecting a marker produced by Machine 1)\n",
    "- $P(M_2) = 0.20$ (Probability of selecting a marker produced by Machine 2)\n",
    "- $P(M_3) = 0.50$ (Probability of selecting a marker produced by Machine 3)\n",
    "- $P(D|M_1) = 0.05$ (Probability of selecting a defective marker given it was produced by Machine 1)\n",
    "- $P(D|M_2) = 0.03$ (Probability of selecting a defective marker given it was produced by Machine 2)\n",
    "- $P(D|M_3) = 0.01$ (Probability of selecting a defective marker given it was produced by Machine 3)\n",
    "\n",
    "We want to find:\n",
    "- $P(D|M_3)$(Probability of selecting a defective marker that was produced by Machine 3)\n",
    "\n",
    "To find $P(D|M_3)$, we can use Bayes' theorem, which states:\n",
    "\n",
    "$$P(D|M_3) = \\frac{P(M_3|D) \\times P(D)}{P(M_3)}$$\n",
    "\n",
    "Where:\n",
    "- $P(M_3|D)$ is the probability of selecting a marker produced by Machine 3 given that it is defective. Since we are directly given $P(D|M_3) = 0.01$, we don't need to calculate it separately.\n",
    "- $P(D)$ is the overall probability of selecting a defective marker, which is the weighted average of the defective rates of all three machines:\n",
    "\n",
    "$$P(D) = P(D|M_1) \\times P(M_1) + P(D|M_2) \\times P(M_2) + P(D|M_3) \\times P(M_3)$$\n",
    "\n",
    "$$P(D) = 0.05 \\times 0.20 + 0.03 \\times 0.20 + 0.01 \\times 0.50$$\n",
    "\n",
    "$$P(D) = 0.01 + 0.006 + 0.005 = 0.021$$\n",
    "\n",
    "Now, we can plug in the values into Bayes' theorem:\n",
    "\n",
    "$$P(D|M_3) = \\frac{0.01 \\times 0.021}{0.50} = \\frac{0.00021}{0.50}$$\n",
    "\n",
    "$$P(D|M_3) = 0.00042$$\n",
    "\n",
    "So, the probability of selecting a defective marker that was produced by Machine 3 is 0.00042."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
