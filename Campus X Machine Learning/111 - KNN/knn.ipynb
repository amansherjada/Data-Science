{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfa19ef-2981-43df-a383-b81d36e52630",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:679/1*n9v1xsBi0bek98rqBnWGEg.gif)\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple yet powerful algorithm used for both classification and regression tasks. The logic behind KNN is straightforward:\r\n",
    "\r\n",
    "1. **Training Phase**: In the training phase, the algorithm simply memorizes the feature vectors and corresponding labels of the training data. \r\n",
    "\r\n",
    "2. **Prediction Phase**:\r\n",
    "   - For a given unlabeled data point, KNN calculates the distances between this point and all other points in the training set. The distance metric used can vary, but commonly used ones include Euclidean distance, Manhattan distance, or cosine similarity.\r\n",
    "   - It then identifies the K nearest neighbors to the unlabeled point based on these distances.\r\n",
    "   - For classification tasks, it assigns the most common class label among these K neighbors to the unlabeled point.\r\n",
    "   - For regression tasks, it calculates the average or weighted average of the target values of these K neighbors and assigns it to the unlabeled point.\r\n",
    "\r\n",
    "3. **Choosing K**: The choice of K (the number of neighbors) is a hyperparameter that needs to be specified beforehand. It can significantly affect the performance of the algorithm. A smaller value of K can lead to more flexible decision boundaries but may also increase the noise sensitivity, while a larger value of K can smooth out the decision boundaries but may ignore local patterns.\r\n",
    "\r\n",
    "4. **Decision Boundary**: KNN implicitly defines decision boundaries in the feature space based on the nearest neighbors. In classification, these decision boundaries are determined by the class labels of the neighboring points.\r\n",
    "\r\n",
    "In summary, the simple logic behind KNN is to make predictions for new data points based on the majority vote (for classification) or averaging (for regression) of the labels of their nearest neighbors in the training set. It's called \"nearest neighbors\" because the prediction is based on the closest data points in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e913a-a91e-4c94-a8f1-d4304a86c957",
   "metadata": {},
   "source": [
    "KNN = https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bb279-ae47-42f2-9cd6-a4149e2df293",
   "metadata": {},
   "source": [
    "### Step-by-Step explanation of how the K-Nearest Neighbors (KNN) algorithm works:\r\n",
    "\r\n",
    "1. **Data Collection and Preprocessing**:\r\n",
    "   - Collect a dataset consisting of feature vectors (attributes) and corresponding labels (class or target values).\r\n",
    "   - Preprocess the data if necessary by handling missing values, normalizing features, or encoding categorical variables.\r\n",
    "\r\n",
    "2. **Choose the Value of K**:\r\n",
    "   - Select the number of neighbors (K) to consider when making predictions. This is typically chosen based on cross-validation or other validation methods.\r\n",
    "\r\n",
    "3. **Distance Calculation**:\r\n",
    "   - Compute the distance between the new data point (query point) and every point in the training dataset. Common distance metrics include Euclidean distance, Manhattan distance, or cosine similarity.\r\n",
    "   - The choice of distance metric depends on the nature of the data and the problem at hand.\r\n",
    "\r\n",
    "4. **Find K Nearest Neighbors**:\r\n",
    "   - Identify the K training data points that are closest to the query point based on the calculated distances.\r\n",
    "   - These K data points are the \"nearest neighbors\" to the query point.\r\n",
    "\r\n",
    "5. **Majority Voting (Classification) or Average (Regression)**:\r\n",
    "   - For classification:\r\n",
    "     - If the problem is classification, count the number of data points in each class among the K nearest neighbors.\r\n",
    "     - Assign the query point to the class that appears most frequently among its K nearest neighbors. This is known as majority voting.\r\n",
    "   - For regression:\r\n",
    "     - If the problem is regression, take the average (or weighted average) of the target values of the K nearest neighbors.\r\n",
    "     - Assign this average value to the query point as its predicted target value.\r\n",
    "\r\n",
    "6. **Prediction**:\r\n",
    "   - Return the predicted class label (for classification) or predicted target value (for regression) for the query point.\r\n",
    "\r\n",
    "7. **Evaluate Model Performance**:\r\n",
    "   - Assess the performance of the KNN model using appropriate evaluation metrics such as accuracy, precision, recall, F1-score (for classification), or mean squared error (for regression).\r\n",
    "   - Optionally, fine-tune hyperparameters (such as K) to improve performance.\r\n",
    "\r\n",
    "8. **Repeat for New Data**:\r\n",
    "   - Once the model is trained and evaluated, it can be used to make predictions on new, unseen data points usingng data points in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec3e75-6a17-4d65-ace6-e9fb572282f1",
   "metadata": {},
   "source": [
    "### Code Example on *Breast Cancer Wisconsin (Diagnostic) Data Set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b0319d-5e88-4d04-b59a-97980bc513ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a631d8-af0f-42de-8b9c-1689040cc629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43760b2-0762-42f9-86ad-8cb9130d07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 32'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f75de3-1e6f-4c99-b39c-0d7bb7f0ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4484ae15-02a1-4734-b916-a1d14d0550da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c4f1c-5562-489e-aa51-68334e2d6a04",
   "metadata": {},
   "source": [
    "Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "\r\n",
    "- **Malignant**: Malignant tumors are cancerous growths that can invade nearby tissues and spread to other parts of the body. They are characterized by uncontrolled cell growth, often with the ability to metastasize (spread) to distant organs or tissues, which can be life-threatening if not treated promptly.\r\n",
    "\r\n",
    "- **Benign**: Benign tumors are non-cancerous growths that do not invade nearby tissues or spread to other parts of the body. They usually grow slowly and are typically not life-threatening. However, depending on their size and location, benign tumors can sometimes cause health problems or discomfort and may require medical interventealth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fdf242-6d7a-450f-b2ae-f4893ed861ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4506ebb-efb7-43b0-b04f-908f60c64951",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ee8efc-f94c-4d53-923a-e1d6c551aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable 'y' from categorical ('M'/'B') to numerical labels (0/1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fd8c61-bd69-4f19-a292-dd64ca1a6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8cd6ceb-9d91-402e-98bd-03d88ae9d9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f8820-c16b-4c9e-af9e-ee6dd71376a2",
   "metadata": {},
   "source": [
    "#### Data scaling is important in K-Nearest Neighbors (KNN) algorithm for a couple of reasons:\r\n",
    "\r\n",
    "1. **Distance Calculation**: KNN relies on distance metrics to determine the similarity between data points. If the features are on different scales, features with larger magnitudes may dominate the distance calculations. This can lead to biased results where certain features have a disproportionate influence on the outcome. Scaling the features ensures that each feature contributes equally to the distance calculation.\r\n",
    "\r\n",
    "2. **Convergence Speed**: Data scaling can also help improve the convergence speed of the algorithm. When features are on vastly different scales, it may take longer for the algorithm to converge to the optimal solution.\r\n",
    "\r\n",
    "Common methods for scaling data include:\r\n",
    "\r\n",
    "- **Min-Max Scaling**: This method scales the data to a fixed range, usually between 0 and 1. It's calculated as `(x - min(x)) / (max(x) - min(x))`, where `x` is the feature value.\r\n",
    "\r\n",
    "- **Standardization (Z-score Normalization)**: This method scales the data to have a mean of 0 and a standard deviation of 1. It's calculated as `(x - mean(x)) / std_dev(x)`, where `x` is the feature value.\r\n",
    "\r\n",
    "- **Normalization**: This method scales each feature to have a unit norm, meaning that the sum of the squares of the values of each feature is equal to 1. It's calculated as `x / norm(x)`.\r\n",
    "\r\n",
    "Before applying KNN, it's generally a good practice to preprocess the data by scaling it appropriately based on the characteristics of the dataset and the requirements of the algorithm. This ensures that the algorithm performs optimally and is not biased by differences in feature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b081d22d-b5df-40b0-85bf-a83addef6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9dc9b5a-6903-4398-ba8d-b4110632ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01330339,  1.7757658 , -0.01491962, ..., -0.13236958,\n",
       "        -1.08014517, -0.03527943],\n",
       "       [-0.8448276 , -0.6284278 , -0.87702746, ..., -1.11552632,\n",
       "        -0.85773964, -0.72098905],\n",
       "       [ 1.44755936,  0.71180168,  1.47428816, ...,  0.87583964,\n",
       "         0.4967602 ,  0.46321706],\n",
       "       ...,\n",
       "       [-0.46608541, -1.49375484, -0.53234924, ..., -1.32388956,\n",
       "        -1.02997851, -0.75145272],\n",
       "       [-0.50025764, -1.62161319, -0.527814  , ..., -0.0987626 ,\n",
       "         0.35796577, -0.43906159],\n",
       "       [ 0.96060511,  1.21181916,  1.00427242, ...,  0.8956983 ,\n",
       "        -1.23064515,  0.50697397]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fde7068-c36d-4a1e-9d9d-4926056f1063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada595db-254b-4da8-886a-e7c59f18a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a3dc5a-ea94-4066-af30-680f449015fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7bcb36-6212-46c1-b111-1cd405b168f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f405f4-25fe-47f7-91d1-e124447fc281",
   "metadata": {},
   "source": [
    "### How to select (k) n_neighbors=?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf52ecd-7e68-4269-9c93-2009253c329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(1,16):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5da756e-3684-4396-9687-54962d17dfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.956140350877193,\n",
       " 0.9736842105263158,\n",
       " 0.9912280701754386,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9736842105263158,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01418d3-7096-44b4-8b61-2fa03354e80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 0.9912280701754386\n",
      "Index of maximum value: 2\n",
      "Number of 'K': 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value:\",np.max(scores))\n",
    "print(\"Index of maximum value:\", np.argmax(scores))\n",
    "print(\"Number of 'K':\", np.argmax(scores) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78627888-1c4a-4833-bc59-510c106451b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,16), scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45704f1-6325-41e1-b751-35113ef5c590",
   "metadata": {},
   "source": [
    "Optimal Value of K in this example is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14a09717-ba46-4729-8d53-65cb028b7839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912280701754386"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737a919-0ef8-4d42-94ad-370a76c219af",
   "metadata": {},
   "source": [
    "### Decision Surface\n",
    "\n",
    "![DS](https://miro.medium.com/max/520/1*WPUEBVr3-emXrQMKe-03jw.png)\n",
    "\n",
    "A decision surface, also known as a decision boundary, is a conceptual boundary or surface that separates different classes or categories in a classification problem. It represents the regions in the feature space where the classification model assigns different labels or categories to the input data points.\r\n",
    "\r\n",
    "In a binary classification problem, where there are two classes (e.g., class 0 and class 1), the decision surface is a line, curve, or higher-dimensional surface that divides the feature space into two regions, each corresponding to one of the classes. The decision surface indicates the points at which the classification model changes its prediction from one class to another.\r\n",
    "\r\n",
    "For example, in a 2-dimensional feature space, the decision surface could be a straight line that separates one class from another. In a more complex scenario with higher-dimensional feature spaces, the decision surface may take the form of a hyperplane or a more intricate boundary.\r\n",
    "\r\n",
    "The goal of a classification algorithm is to learn the decision surface from the training data so that it can accurately classify new, unseen data points. Different classification algorithms may result in different decision surfaces depending on their underlying assumptions and methodologies.\r\n",
    "\r\n",
    "Visualizing the decision surface can be helpful for understanding how a classification model makes predictions and how well it generalizes to new data. Techniques such as plotting the decision surface in 2D or 3D (for visualization purposes) can provide insights into the model's behavior and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ccd78e-dd42-4e9c-b754-d2f0a99a58fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bbd3e30-649e-40bf-9e11-2e77bf313839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b9f1c-c304-41d9-a143-ddd4a8d3ff24",
   "metadata": {},
   "source": [
    "### Overfitting and Underfitting in KNN\n",
    "\n",
    "Overfitting and Underfitting are two common issues that can occur when training a model like K-Nearest Neighbors (KNN).\n",
    "\n",
    "1. **Overfitting**:\n",
    "   - Overfitting occurs when a model learns the training data too well, including noise or random fluctuations. As a result, the model performs well on the training data but fails to generalize to new, unseen data.\n",
    "   - In KNN, overfitting can occur if the value of **`k` (the number of nearest neighbors) is too small**. A small value of `k` can lead to a complex decision boundary that closely follows the training data, including its noise.\n",
    "   - Additionally, having too many features or irrelevant features in the dataset can also contribute to overfitting in KNN, as it may lead to high-dimensional feature spaces where the notion of proximity becomes less meaningful.\n",
    "\n",
    "2. **Underfitting**:\n",
    "   - Underfitting occurs when a model is too simple to capture the underlying structure of the data. As a result, the model performs poorly on both the training and test data.\n",
    "   - In KNN, **underfitting can occur if the value of `k` is too large**. A large value of `k` can lead to a simple decision boundary that ignores local variations in the data.\n",
    "   - Additionally, underfitting in KNN can occur if the number of neighbors is too small relative to the complexity of the dataset, leading to a lack of sensitivity to the underlying patterns.\n",
    "\n",
    "To address overfitting and underfitting in KNN, you can:\n",
    "\n",
    "- **Optimize the value of `k`**: Experiment with different values of `k` and use techniques like cross-validation to find the optimal value that balances bias and variance.\n",
    "- **Feature selection and dimensionality reduction**: Select relevant features and reduce the dimensionality of the feature space to mitigate the risk of overfitting, especially in high-dimensional datasets.\n",
    "- **Regularization**: Techniques like feature scaling or distance weighting can help mitigate the influence of irrelevant features or noisy data points.\n",
    "- **Ensemble methods**: Combine multiple KNN models with different `k` values or other classifiers to reduce the risk of overfitting or underfitting.\n",
    "- **Model evaluation**: Use techniques like learning curves, validation curves, and holdout validation to diagnose and address overfitting and underfitting issues.\n",
    "\n",
    "Overall, finding the right balance between model complexity and generalization is crucial in mitigating the risks of overfitting and underfitting in KNN and other machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125543a3-310c-4979-baf6-e09cdcb1500c",
   "metadata": {},
   "source": [
    "### Limitations of KNN\n",
    "\n",
    "While K-Nearest Neighbors (KNN) is a simple and intuitive algorithm, it comes with several limitations:\r\n",
    "\r\n",
    "1. **Computationally expensive**: KNN requires computing the distances between the query point and all training samples, which can be computationally expensive, especially for large datasets. As the dataset grows, the computational cost of predicting new instances increases linearly with the number of samples.\r\n",
    "\r\n",
    "2. **Memory-intensive**: KNN stores all the training data, which can consume a significant amount of memory, especially for large datasets with many features or high-dimensional data.\r\n",
    "\r\n",
    "3. **Sensitive to irrelevant features**: KNN considers all features equally when computing distances between data points. If the dataset contains irrelevant or noisy features, it can negatively impact the performance of KNN.\r\n",
    "\r\n",
    "4. **Needs feature scaling**: KNN's performance can be influenced by the scale of features. Features with larger scales may dominate the distance calculations, leading to biased results. Therefore, it's essential to scale the features before applying KNN.\r\n",
    "\r\n",
    "5. **Requires appropriate distance metric**: The choice of distance metric in KNN (e.g., Euclidean distance, Manhattan distance, etc.) can significantly impact the algorithm's performance. Selecting an appropriate distance metric depends on the characteristics of the dataset and the problem domain.\r\n",
    "\r\n",
    "6. **Insensitive to local structure**: KNN treats all neighbors equally and does not consider the local structure or density of data points. As a result, it may perform poorly in datasets with complex or nonlinear decision boundaries.\r\n",
    "\r\n",
    "7. **Difficulty handling high-dimensional data**: In high-dimensional spaces, the notion of distance becomes less meaningful, a phenomenon known as the curse of dimensionality. This can lead to degraded performance and increased computational complexity for KNN.\r\n",
    "\r\n",
    "8. **Imbalanced datasets**: KNN may not perform well on imbalanced datasets where one class significantly outnumbers the others. It tends to favor the majority class, leading to biased predictions.\r\n",
    "\r\n",
    "9. **No model representation**: Unlike parametric models (e.g., linear regression, logistic regression), KNN does not learn a model representation from the training data. Instead, it memorizes the entire training dataset, making it challenging to interpret the learned relationships between features and target.\r\n",
    "\r\n",
    "10. **Sensitive to noisy data**: KNN is sensitive to noisy data points, outliers, and missing values, as they can significantly impact the computed distances and subsequently the predictions.\r\n",
    "\r\n",
    "Despite these limitations, KNN remains a popular choice for classification and regression tasks, especially for small to medium-sized datasets with relatively low computational requirements. However, it's essential to understand its limitations and consider them when applying the algorithm to real-world problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
